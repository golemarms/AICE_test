{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlp\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = mlp.setup.load_config()\n",
    "\n",
    "preprocess_dict = config[\"Preprocessing\"]\n",
    "\n",
    "preprocess_dict\n",
    "\n",
    "## helper functions\n",
    "\n",
    "def drop_duplicates(df):\n",
    "    return df.drop_duplicates(['date', 'hr'])\n",
    "\n",
    "def correct_weather_typos(df):\n",
    "    pairs_list = [(search_string,value) for value, search_string in preprocess_dict['weather_search_strings'].items()]\n",
    "    to_replace, value = list(zip(*pairs_list))\n",
    "    \n",
    "    def correct_weather(df):\n",
    "        return df.assign(weather = lambda x: x.weather.str.lower().\\\n",
    "                          replace(to_replace=to_replace, value=value, regex=True))\n",
    "    \n",
    "    return df.pipe(correct_weather)\n",
    "\n",
    "def encode_weather_ordinal(df):\n",
    "    \n",
    "    weather_ord_encoding = preprocess_dict['weather_ord_encoding']\n",
    "    weather, ordinal = list(zip(*weather_ord_encoding.items()))\n",
    "    lookup_weather = pd.Series(index=weather,\n",
    "                               data=ordinal,\n",
    "                               name=\"weather_encoded\")\n",
    "    \n",
    "    return df.merge(lookup_weather, left_on=\"weather\", right_index=True).sort_values([\"date\", \"hr\"]).drop(columns=\"weather\")\n",
    "\n",
    "# remove guest_scooter and registered_scooter values below 0\n",
    "\n",
    "def remove_negative_scooters(df):\n",
    "    negative_mask = (df.guest_scooter < 0) | (df.registered_scooter < 0)\n",
    "    return df.loc[~negative_mask]\n",
    "\n",
    "# remove entries which have anomalous feels_like_temperature values\n",
    "\n",
    "def remove_anomalous_temps(df):\n",
    "    def get_z_score(df, col):\n",
    "        df_new = df.copy()\n",
    "        df_new[col+\"_z_score\"] = (df[col] - df[col].mean())/ df[col].std()\n",
    "        return df_new\n",
    "\n",
    "    df = df.pipe(get_z_score, \"temperature\").\\\n",
    "         pipe(get_z_score, \"feels_like_temperature\").\\\n",
    "         assign(z_score_diff_abs = lambda x: (x.temperature_z_score - x.feels_like_temperature_z_score).abs())\n",
    "    \n",
    "    z_threshold = preprocess_dict[\"z_threshold\"]\n",
    "    \n",
    "    df[\"above_threshold\"] = df[\"z_score_diff_abs\"] > z_threshold\n",
    "    \n",
    "    return df.query(\"not above_threshold\").drop(columns=[\"temperature_z_score\",\n",
    "                                                         \"feels_like_temperature_z_score\",\n",
    "                                                         \"z_score_diff_abs\",\n",
    "                                                         \"above_threshold\"])\n",
    "\n",
    "def create_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['datetime'] = pd.to_datetime(df.date + ' ' + df.hr.astype(str) + \":00\")\n",
    "    \n",
    "    df['is_weekend'] = df.datetime.dt.dayofweek.isin([5,6])\n",
    "    df['month'] = df.datetime.dt.month\n",
    "    \n",
    "    rush_hours = preprocess_dict['rush_hours']\n",
    "    df['is_rush_hour'] = df.hr.isin(rush_hours)\n",
    "    \n",
    "    def encode_cyclic(df, var, period):\n",
    "        df_new = df.copy()\n",
    "        df_new[ var + \"_y\"] = np.sin(2*np.pi*df[var]/period)\n",
    "        df_new[ var + \"_x\"] = np.cos(2*np.pi*df[var]/period)\n",
    "\n",
    "        return df_new\n",
    "    \n",
    "    return df.pipe(encode_cyclic, \"hr\", 24)\\\n",
    "             .pipe(encode_cyclic, \"month\", 12)\\\n",
    "             .drop(columns=[\"date\", \"datetime\", \"hr\", \"month\"])\n",
    "\n",
    "def combine_scooter_vars(df):\n",
    "    return df.assign(total_scooter=lambda x: x.guest_scooter + x.registered_scooter)\\\n",
    "              .drop(columns = [\"guest_scooter\", \"registered_scooter\"])\n",
    "\n",
    "def preprocess(raw_df):\n",
    "    return raw_df.pipe(drop_duplicates)\\\n",
    "                 .pipe(correct_weather_typos)\\\n",
    "                 .pipe(remove_negative_scooters)\\\n",
    "                 .pipe(remove_anomalous_temps)\\\n",
    "                 .pipe(encode_weather_ordinal)\\\n",
    "                 .pipe(create_time_features)\\\n",
    "                 .pipe(combine_scooter_vars).corr().style.background_gradient(cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mlp.setup.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_dict = config[\"Preprocessing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weather_search_strings': {'clear': '\\\\w*l\\\\w+r$',\n",
       "  'cloudy': '\\\\w*l\\\\w+dy$',\n",
       "  'light snow/rain': '\\\\w*l\\\\w+t snow.*'},\n",
       " 'weather_ord_encoding': {'clear': 0,\n",
       "  'cloudy': 1,\n",
       "  'light snow/rain': 2,\n",
       "  'heavy snow/rain': 3},\n",
       " 'z_threshold': 1.5,\n",
       " 'rush_hours': [8, 17, 18]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "    return df.drop_duplicates(['date', 'hr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_weather_typos(df):\n",
    "    pairs_list = [(search_string,value) for value, search_string in preprocess_dict['weather_search_strings'].items()]\n",
    "    to_replace, value = list(zip(*pairs_list))\n",
    "    \n",
    "    def correct_weather(df):\n",
    "        return df.assign(weather = lambda x: x.weather.str.lower().\\\n",
    "                          replace(to_replace=to_replace, value=value, regex=True))\n",
    "    \n",
    "    return df.pipe(correct_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_weather_ordinal(df):\n",
    "    \n",
    "    weather_ord_encoding = preprocess_dict['weather_ord_encoding']\n",
    "    weather, ordinal = list(zip(*weather_ord_encoding.items()))\n",
    "    lookup_weather = pd.Series(index=weather,\n",
    "                               data=ordinal,\n",
    "                               name=\"weather_encoded\")\n",
    "    \n",
    "    return df.merge(lookup_weather, left_on=\"weather\", right_index=True).sort_values([\"date\", \"hr\"]).drop(columns=\"weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove guest_scooter and registered_scooter values below 0\n",
    "\n",
    "def remove_negative_scooters(df):\n",
    "    negative_mask = (df.guest_scooter < 0) | (df.registered_scooter < 0)\n",
    "    return df.loc[~negative_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries which have anomalous feels_like_temperature values\n",
    "\n",
    "def remove_anomalous_temps(df):\n",
    "    def get_z_score(df, col):\n",
    "        df_new = df.copy()\n",
    "        df_new[col+\"_z_score\"] = (df[col] - df[col].mean())/ df[col].std()\n",
    "        return df_new\n",
    "\n",
    "    df = df.pipe(get_z_score, \"temperature\").\\\n",
    "         pipe(get_z_score, \"feels_like_temperature\").\\\n",
    "         assign(z_score_diff_abs = lambda x: (x.temperature_z_score - x.feels_like_temperature_z_score).abs())\n",
    "    \n",
    "    z_threshold = preprocess_dict[\"z_threshold\"]\n",
    "    \n",
    "    df[\"above_threshold\"] = df[\"z_score_diff_abs\"] > z_threshold\n",
    "    \n",
    "    return df.query(\"not above_threshold\").drop(columns=[\"temperature_z_score\",\n",
    "                                                         \"feels_like_temperature_z_score\",\n",
    "                                                         \"z_score_diff_abs\",\n",
    "                                                         \"above_threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_features(df):\n",
    "    df = df.copy()\n",
    "    df['datetime'] = pd.to_datetime(df.date + ' ' + df.hr.astype(str) + \":00\")\n",
    "    \n",
    "    df['is_weekend'] = df.datetime.dt.dayofweek.isin([5,6])\n",
    "    df['month'] = df.datetime.dt.month\n",
    "    \n",
    "    rush_hours = preprocess_dict['rush_hours']\n",
    "    df['is_rush_hour'] = df.hr.isin(rush_hours)\n",
    "    \n",
    "    def encode_cyclic(df, var, period):\n",
    "        df_new = df.copy()\n",
    "        df_new[ var + \"_y\"] = np.sin(2*np.pi*df[var]/period)\n",
    "        df_new[ var + \"_x\"] = np.cos(2*np.pi*df[var]/period)\n",
    "\n",
    "        return df_new\n",
    "    \n",
    "    return df.pipe(encode_cyclic, \"hr\", 24)\\\n",
    "             .pipe(encode_cyclic, \"month\", 12)\\\n",
    "             .drop(columns=[\"date\", \"datetime\", \"hr\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_scooter_vars(df):\n",
    "    return df.assign(total_scooter=lambda x: x.guest_scooter + x.registered_scooter)\\\n",
    "              .drop(columns = [\"guest_scooter\", \"registered_scooter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess(raw_df):\n",
    "    return raw_df.pipe(drop_duplicates)\\\n",
    "                 .pipe(correct_weather_typos)\\\n",
    "                 .pipe(remove_negative_scooters)\\\n",
    "                 .pipe(remove_anomalous_temps)\\\n",
    "                 .pipe(encode_weather_ordinal)\\\n",
    "                 .pipe(create_time_features)\\\n",
    "                 .pipe(combine_scooter_vars).corr().style.background_gradient(cmap=\"RdYlGn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
